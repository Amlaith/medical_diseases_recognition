# Рекомендации по применению методов глубокого обучения для задачи распознавания заболеваний лёгких
## Анализ текущей ситуации:
    Решается задача классификации рентгеновских снимков лёгких на 3 класса:

    Lung Opacity (затемнение в лёгких, есть bounding box)
    No Lung Opacity / Not Normal (нет затемнения, нет bounding box, но есть патология)
    Normal (здоровые лёгкие)

    Классические ML-подходы (особенно SVM с линейным ядром после SVD) показали относительно неплохие результаты, но:

    - Требуют значительного предварительного снижения размерности (с 1024×1024 до 128 компонент)
    - Ограничены в способности выделять сложные паттерны на медицинских изображениях
    - Основные метрики оценки: F1-score (weighted), Win-norm (кастомная), ROC-AUC, Gini
    - Дисбаланс классов является серьёзной проблемой

## Рекомендации по применению Deep Learning


1. Архитектуры для классификации
    1.1. Предобученные CNN модели (рекомендуется начать с них)

    | Модель | Преимущества | Особенности применения |
    |--------|--------------|------------------------|
    | ResNet-18/50/101 | Это база, всегда стоит начинать решать задачу с резнета18 |  |
    | DenseNet-121 | Показала отличные результаты в CheXNet (Stanford), специально для мед. снимков | Хорошо сохраняет детали благодаря плотным связям |
    | EfficientNet-B0/B3 | Наилучший баланс точности/вычислительной сложности | Подходит при ограниченных ресурсах |

    1.2. Специализированные медицинские модели
    CheXNet-подобная архитектура: Адаптированная DenseNet-121, специально обученная на задачах классификации патологий лёгких
    MedicalNet: Предобученная 3D-ResNet для медицинских изображений (если будете работать с 3D данными)

2. Подготовка данных для DL
- **Препроцессинг и аугментация**:
   - Стандартизация размера: 224×224 или 299×299 (в зависимости от модели)
   - Нормализация: по ImageNet (μ=[0.485, 0.456, 0.406], σ=[0.229, 0.224, 0.225])
   - Аугментации для медицинских изображений:
     - Малые повороты (±10°)
     - Небольшие сдвиги (±10%)
     - Масштабирование (0.9-1.1)
     - Небольшой шум Гаусса
     - CLAHE (Contrast Limited Adaptive Histogram Equalization)
     - Что-то еще на ваш вкус. НЕ перебарщивайте с сложными аугментациями

- **Решение проблемы дисбаланса классов**:
   - Weighted sampling в DataLoader (посчитать веса для классов)
   - Focal Loss вместо Cross-Entropy
   - Class weights в функции потерь
   - Стратегия oversampling редких классов

3. Архитектуры для детекции (на будущее, надеюсь очень близкое :) )
Учитывая, что в перспективе планируется задача детекции (поиск bounding box):

| Модель | Преимущества | Комментарии |
|--------|--------------|-------------|
| YOLO v5/v8/ваша любимая | Высокая скорость инференса | Подойдет если важна скорость. Очень просто начать эксперименты с помощью библиотеки Ultralytics |
| RetinaNet | Высокая точность, focal loss против дисбаланса | Подходит для маленьких объектов |
| Faster R-CNN | Отличный баланс качество/скорость, чаще всего можно найти в проде | Большое количество предобученных моделей |
| EfficientDet | Эффективно использует вычислительные ресурсы | Хорошо масштабируется |

### Пример плана экспериментов:

1. **Базовая модель (1-2 дня)**:
    - Использовать предобученный ResNet-18 или DenseNet
    - Заморозить веса и обучить только классификационную голову
    - Базовые аугментации и взвешенная кросс-энтропия

2. **Fine-tuning (2-3 дня)**:
    - Разморозить последние 1-2 блока базовой модели
    - Экспериментировать с learning rate (циклический LR, One-cycle policy)
    - Применить более продвинутые аугментации

3. **Решение проблемы дисбаланса (2-3 дня)**:
    - Протестировать Focal Loss
    - Применить взвешенную выборку

4. **Ансамблирование (1-2 дня)**:
    - Объединить 3-5 лучших моделей
    - Протестировать разные стратегии: stacking, voting, bagging

5. Продвинутые техники для улучшения качества 
    1. **Attention-механизмы**:
        - Squeeze-and-Excitation blocks
        - Self-attention для выделения зон интереса
        - Residual attention

    2. **Визуализация и интерпретация**:
        - Grad-CAM для определения зон внимания модели
        - SHAP values для объяснения предсказаний
        - Интеграция этих методов в интерфейс для помощи врачам

    3. **Комбинирование признаков из разных источников**:
        - Объединение CNN-признаков и метаданных пациентов
        - Multi-modal fusion для улучшения предсказаний

6. Техническая реализация

    1. **Фреймворки**:
    - PyTorch Lightning (советую)
    - PyTorch + fastai (удобство и скорость экспериментов)

    2. **Инфраструктура**:
    - wandb\MLflow\clearml для трекинга экспериментов
    - Сохраняйте веса обученных моделей. Можно попробовать DVC для версионирования данных
    - ONNX для экспорта моделей в прод

### Примерные ресурсы для обучения:

| Архитектура | Мин. GPU память | Рекомендуемый batch size | Примерное время обучения |
|-------------|----------------|--------------------------|--------------------------|
| ResNet-50   | 8 GB           | 16-32                    | 3-5 часов                |
| DenseNet-121| 12 GB          | 16-24                    | 4-6 часов                |
| EfficientNet-B3 | 8 GB       | 12-16                    | 5-7 часов                |
| RetinaNet   | 16 GB          | 4-8                      | 12-24 часов              |


### Потенциальные проблемы и их решения
1. Переобучение:
- Добавление аугментаций
- Early stopping
- Регуляризация (weight decay, dropout)
- Stochastic Weight Averaging

2. Ограниченные данные:

- Self-supervised pretraining
- Contrastive learning
- Transfer learning с моделями, предобученными на других медицинских датасетах


Переход от классических ML-методов к глубокому обучению должен давать значительный буст к качеству в классификации патологий. Начиная с предобученных CNN, двигаясь к специализированным архитектурам и техникам для медицинских изображений, можно добиться существенного улучшения всех метрик по сравнению с текущими бейзлайнами.
Учитывая медицинскую природу задачи, рекомендуется уделить особое внимание интерпретируемости модели и оценке уверенности в предсказаниях, что критично для применения в реальной клинической практике.

У вас все получится :)