# Чекпоинт 3. Выбор метрик. Построение бейзлайна.

## Abstract
1. Удалось получить модели относительно приличного качества **только линейными преобразованиями и SVM с линейным ядром**.
2. Выбрали метрики для быстрой оценки моделей в быстрых экспериментах: `f1_score(weighted)`, `win_norw(custom)`. 
3. Выбрали метрики для общей оценки моделей: `confusion matrix`, `ROC-AUC`, `Gini`, `Roc-curve`, `DET-curve`.

## Описание задачи на чекпоинт 3
В следующем семестре планируется реализовать задачу детекции. В этом чекпоинте мы занимались задачей классификации. Есть 3 класса. 
|Label|Text Label|Desc|Has Bounding Box|
|:-|:-|:-|:-|
|0|Lung Opacity|Есть затемнение в лёгких, есть bounding box|Yes|
|1|No Lung Opacity / Not Normal|Нет затемнения в лёгких, нет bounding box, но есть патология|No|
|2|Normal|Здоровые лёгкие|No|

Нам могут пригодиться модели трёх видов:
|#|Классы|Вид задачи классификации|Desc|
|:-|:-|:-|:-|
|1|healthy / not healty|binary|Наблюдается ли какая-либо патология|
|2|has bbox / not has bbox|binary|Есть ли bounding box обозначающий пневмонию|
|3|normal / pneumonia / other pathology|multiple|Различение всех классов|

В сервисе в чекпоинте 4 в сервисе будет модель `multiclass`. Задача не предполагает хорошее качество без deep learning, поэтому победа - это **получить модель качеством лучше, чем константная модель, которая всегда предсказывает мажоритарный класс**.

## Метрики
Факторы, влияющие на выбор метрик:
* Наблюдается дисбаланс классов во всех подзадачах
* Нам одинаково "страшно" ошибаться во все стороны. В следующих чекпоинтах будет учитываться, что цена ошибки очень высока.
* Нам нужно 2 типа метрик: для быстрой оценки и сравнения моделей, и для более вдумчивого анализа.
* Метрики должны быть легко интерпретируемы, визуальны, если возможно.

|Группа метрик|Метрики|Ситуация использования|
|:-|:-|:-|
|"Быстрые"|`f1-score (weighted)`, `Win-norm (кастомная)`|Eсли нужно оценить модель в моменте при быстрых экспрементах|
|"Вдумчивые"|`confusion matrix`, `ROC-AUC`, `Gini`, `RocCurve`, `DETCurve`|Для более вдумчивого анализа|

### Кастомная метрика "Нормированный выйгрыш" или Win-norm
$$Win_{norm} = \frac{F1 -Prop}{1 - Prop},$$ 

где
* $Prop$ - доля мажоритарного класса
* $F1$ - f1-score

Обозначает величину выигрыша от того что было возможно выиграть.
* Принимает значения от $-\infty$ до $1$ 
* В идеале 1. Модель не ошибается.
* 0 - качесто предсказаний модели такое же, какое у константной модели
* Если значение отрицательное, то качество модели хуже, чем у константной модели

Эта метрика идеально отвечает задачам чекпоинта. Цель - **получить положительный Win-norm**.

### Интегральные метрики
Использовать коэффициент Gini предпочтительнее, его немного проще оценить без картинки. Т.к. в нём не учитывается треугольник ниже уровня шансов. Если в дополнение исользовать ROC кривую, то совсем нет разницы что именно использвать.

![График с интегральными метриками (Roc-curve и DET)](https://raw.githubusercontent.com/Amlaith/medical_diseases_recognition/refs/heads/main/checkpoint_3_baseline/md_media/roc_det_curve_bbox_clf.png)


## Описание построения бейзлайна
Хочется получить наилучшие модели наименьшими усилиями. Мы проводим эксперименты, очень хочется чтобы датасеты помещались в память. Брали воспроизводимые выборки. Основная часть работы была в предобработке данных, для достижения задач чекпоинта хватило SVM (Метода опорных векторов).

### Первые шаги
На первой итерации изображения просто сжимались via OpenCV. Перебрались разные сочетания сжатия и кол-ва изображений в выборке. В двух подзадачах: "здоров/не здоров" и multiclass цель была достигнута моментально.

Лучшие результаты с сжатием изображения:
|Подзадачачи|Сжатие|Размер выбоки|Win-norm|
|:-|:-|:-|:-|
|is healthy|1024x1024 $\rightarrow$ 128x128|2500|0.1772|
|is has bbox|1024x1024 $\rightarrow$ 128x128|2500|-0.1018|
|multiclass|1024x1024 $\rightarrow$ 64x64|10000|0.1226|

### PCA via SVD
На второй итерации вспомнились лекции по математике. Притом, по счастливому совпадению, это линейные преобразования. 
![svd показательство visul](https://raw.githubusercontent.com/Amlaith/medical_diseases_recognition/refs/heads/main/checkpoint_3_baseline/md_media/components_graph_2.png)

Оказалось, что у нас сингулярыне числа в SVD разложении очень быстро убывают. Можно ощутимо уменьшить признаковое пространство.
![svd показательство visul](https://raw.githubusercontent.com/Amlaith/medical_diseases_recognition/refs/heads/main/checkpoint_3_baseline/md_media/components_graph_3.png)
После неторого n, каждая новая компонента перестанет приносить новую информацию.

Снижение размерности данных  1024x1024 features $\rightarrow$ 128 features, оказалось достаточным решением. Получили требуемое качество по всем моделям. 
|Подзадачача|Снижение размерности |Размер выбоки|Win-norm (Linear)| Win-norm (Non Linear)|Gini (Linear)| Gini (Non Linear)|
|:-|:-|:-|:-|:-|:-|:-|
|is healthy|1024x1024 $\rightarrow$ 128|5000|0.3472|0.4298|0.4851|0.5030|
|is has bbox|1024x1024 $\rightarrow$ 128|5000|0.2515|0.2500|0.3859|0.4327|
|multiclass|1024x1024 $\rightarrow$ 128|5000|0.3106|0.3777|0.6716\*|0.6993\*|

\* one vs rest

### Feature extraction via SIFT
Также пробовалось использовать SIFT, он показал приличные результаты, но хуже, чем сжатие изображения.

## Итоги
Поставленные цели выполнены. 
1. Выбраны метрики числовые и интегральные
2. Получилось получить положительный Win-norm. Оказалось, что **можно было остановиться на линейных преобразованиях и линейных моделях**.
3. Построен пайплайн и написан отчёт
